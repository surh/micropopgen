{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# Copyright (C) 2017 Sur Herrera Paredes\n",
    "\n",
    "# Imports\n",
    "import os\n",
    "import sutilspy\n",
    "import csv\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arguments for ipython\n",
    "args = argparse.Namespace()\n",
    "args.indir = \"/home/sur/micropopgen/exp/2017/today5/test/\"\n",
    "args.test = \"MK\"\n",
    "args.outfile = \"/home/sur/micropopgen/exp/2017/today5/mk_results.txt\"\n",
    "args.metadata_file = \"/home/sur/micropopgen/exp/2017/today5/map.txt\"\n",
    "args.group1 = \"Supragingival plaque\"\n",
    "args.group2 = \"Tongue dorsum\"\n",
    "args.min_count = 1\n",
    "args.nrows = float('inf')\n",
    "args.tables = '/home/sur/micropopgen/exp/2017/today5/tables.txt'\n",
    "args.pseudocount = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class GenomeSite:\n",
    "    \"\"\"A class for represintinc sites in genome that have potential SNPS\"\"\"\n",
    "    \n",
    "    def __init__(self,site_id, contig, position, ref_allele = '',\n",
    "                 major_allele = '',\n",
    "                 minor_allele = '', locus_type = '', gene_id = '',\n",
    "                 aminoacid_A = '',\n",
    "                 aminoacid_C = '', aminoacid_G = '', aminoacid_T = ''):\n",
    "        self.id = site_id\n",
    "        self.contig = contig\n",
    "        self.position = position\n",
    "        self.ref_allele = ref_allele\n",
    "        self.major_allele = major_allele\n",
    "        self.minor_allele = minor_allele\n",
    "        self.locus_type = locus_type\n",
    "        self.gene_id = gene_id\n",
    "        self.aminoA = aminoacid_A\n",
    "        self.aminoC = aminoacid_C\n",
    "        self.aminoG = aminoacid_G\n",
    "        self.aminoT = aminoacid_T\n",
    "    \n",
    "    def codon_aminoacid(self, base):\n",
    "        if base in ['A','a']:\n",
    "            return(self.aminoA)\n",
    "        elif base in ['C','c']:\n",
    "            return(self.aminoC)\n",
    "        elif base in ['G','g']:\n",
    "            return(self.aminoG)\n",
    "        elif base in ['T','t']:\n",
    "            return(self.aminoT)\n",
    "        else:\n",
    "            raise ValueError(\"base must be one of the four canonical nucleoties\")\n",
    "    \n",
    "    def substitution_type(self):\n",
    "        substitution_type = ''\n",
    "        if self.codon_aminoacid(base = self.major_allele) == self.codon_aminoacid(base = self.minor_allele):\n",
    "            substitution_type = 'synonymous'\n",
    "        else:\n",
    "            substitution_type = 'non-synonymous'\n",
    "        \n",
    "        return(substitution_type)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Gene:\n",
    "    \"\"\"A class for representing a gene\"\"\"\n",
    "    \n",
    "    def __init__(self, gene_id,contig,start,end, strand = ''):\n",
    "        if(start > end):\n",
    "            raise ValueError(\"Start cannot be greater than end\")\n",
    "        self.id = gene_id\n",
    "        self.contig = contig\n",
    "        self.start = int(start)\n",
    "        self.end = int(end)\n",
    "        self.strand = strand\n",
    "    \n",
    "    def extend(self, pos):\n",
    "        pos = int(pos)\n",
    "        if pos > self.end:\n",
    "            self.end = pos\n",
    "        elif pos < self.start:\n",
    "            self.start = pos\n",
    "    \n",
    "    def print(self):\n",
    "        print(\"===Gene===\")\n",
    "        print(\">Gene id: {}\".format(self.id))\n",
    "        print(\">Gene contig: {}\".format(self.contig))\n",
    "        print(\">Gene start: {}\".format(str(self.start)))\n",
    "        print(\">Gene end: {}\".format(str(self.end)))\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MKtest:\n",
    "    \"\"\"A class for holding the McDonald-Kreitmant test\"\"\"\n",
    "    \n",
    "    def __init__(self, name, Ds = 0, Dn = 0, Ps = 0, Pn = 0):\n",
    "        self.name = name\n",
    "        self.Dn = Dn\n",
    "        self.Ds = Ds\n",
    "        self.Ps = Ps\n",
    "        self.Pn = Pn\n",
    "    \n",
    "    def update(self, Ds = 0, Dn = 0, Ps = 0, Pn = 0):\n",
    "        \"\"\"Update the contigency matrix\"\"\"\n",
    "        self.Dn += Dn\n",
    "        self.Ds += Ds\n",
    "        self.Ps += Ps\n",
    "        self.Pn += Pn\n",
    "    \n",
    "    def mk_ratio(self, pseudocount = 0):\n",
    "        \"\"\"Calculate the McDonald Kreitman ratio\"\"\"\n",
    "        ratio = ((self.Dn + pseudocount) / (self.Ds + pseudocount)) \\\n",
    "                / ((self.Pn + pseudocount) / (self.Ps) + pseudocount)\n",
    "        return(ratio)\n",
    "    \n",
    "    def alpha(self, pseudocount = 0):\n",
    "        \"\"\"Calculate the Smith & Eyre-Walker alpha\"\"\"\n",
    "        alpha = 1 - (((self.Ds + pseudocount) * (self.Dn + pseudocount)) \\\n",
    "                     / ((self.Ps + pseudocount) * (self.Pn + pseudocount)))\n",
    "        return(alpha)\n",
    "    \n",
    "    def hg_test(self, pseudocount = 0):\n",
    "        \"\"\"Hypergeometric (Fisher's exact) test\"\"\"\n",
    "        \n",
    "        res = stats.fisher_exact([[self.Ds + pseudocount,self.Ps + pseudocount],\n",
    "                                  [self.Dn + pseudocount,self.Pn + pseudocount]])\n",
    "        return(res)\n",
    "    \n",
    "    def g_test(self, correction, pseudocount = 0):\n",
    "        \"\"\"G-test for independence. Original McDonald & Kreitman 1991 suggestion\"\"\"\n",
    "        \n",
    "        # Create 2x2 contingency matrix\n",
    "        mat = np.matrix([[self.Ds + pseudocount,self.Ps + pseudocount],\n",
    "                         [self.Dn + pseudocount,self.Pn + pseudocount]])\n",
    "        \n",
    "        if correction == 'none':\n",
    "            res = stats.chi2_contingency(observed=mat,\n",
    "                                         lambda_=\"log-likelihood\",\n",
    "                                         correction=False)\n",
    "        elif correction == 'yates':\n",
    "            # apply yates correction, the default and only option\n",
    "            # on scipy.stats\n",
    "            res = stats.chi2_contingency(observed=mat,\n",
    "                                         lambda_=\"log-likelihood\",\n",
    "                                         correction=True)\n",
    "        elif correction == \"williams\":\n",
    "            # Original correction used by McDonald & Kreitman (1991).\n",
    "            # According to McDonald (same as above) biostat handbook,\n",
    "            # it doesn't make much difference (http://www.biostathandbook.com/small.html)\n",
    "            g, p, df, e = stats.chi2_contingency(observed=mat,\n",
    "                                         lambda_=\"log-likelihood\",\n",
    "                                         correction=False)\n",
    "            \n",
    "            # Calculate q correction\n",
    "            n = mat.sum()\n",
    "            q = 1 \\\n",
    "                + (n * (1 / mat.sum(axis = 1)).sum() - 1) \\\n",
    "                * (n * (1 / mat.sum(axis = 0)).sum() - 1) \\\n",
    "                / (6 * n)\n",
    "                \n",
    "            # correct g and recalculate p-value\n",
    "            g = g / q\n",
    "            p = 1 - stats.chi2.cdf(g, df)\n",
    "            \n",
    "            # combine results\n",
    "            res = [g, p , df, e]\n",
    "            \n",
    "        else:\n",
    "            raise ValueError(\"Corretion must be one of 'none', 'yates' or 'williams'\")\n",
    "        \n",
    "        return(res)\n",
    "    def neutrality_index(self, pseudocount = 1, log = True):\n",
    "        \"\"\"Calculate neutrality index. Following Li et al. (2008), we add a psedocount and return the -log10(NI)\"\"\"\n",
    "        \n",
    "        ni = ((self.Pn + pseudocount) / (self.Dn + pseudocount)) \\\n",
    "            / ((self.Ps + pseudocount) / (self.Ds + pseudocount))\n",
    "        \n",
    "        if log:\n",
    "            ni = -np.log10(ni)\n",
    "        \n",
    "\n",
    "        return(ni)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def confirm_files(args):\n",
    "    \"\"\"Confirm files are present\"\"\"\n",
    "\n",
    "    # Check files exist in input directory\n",
    "    file_list = os.listdir(args.indir)\n",
    "    if 'snps_freq.txt' not in file_list:\n",
    "        raise FileNotFoundError(\"Could not find snps_freq.txt at {}\".format(args.indir))\n",
    "    if 'snps_info.txt' not in file_list:\n",
    "        raise FileNotFoundError(\"Could not find snps_info.txt at {}\".format(args.indir))\n",
    "    if 'snps_depth.txt' not in file_list:\n",
    "        raise FileNotFoundError(\"Could not find snps_depth.txt at {}\".format(args.indir))\n",
    "    if not os.path.isfile(args.metadata_file):\n",
    "        raise FileNotFoundError(\"Could not find metadata file {}\".format(args.metadata_file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    confirm_files(args)\n",
    "\n",
    "    #### Read metadata ####\n",
    "    Groups = sutilspy.io.process_run_list(args.metadata_file,\n",
    "                                          1, 0, header = True)\n",
    "    Samples = sutilspy.io.process_run_list(args.metadata_file,\n",
    "                                           0, 1, header = True)\n",
    "    \n",
    "    ######## Read info #######\n",
    "    Genes = {}\n",
    "    Sites = {}\n",
    "    with open(args.indir + '/snps_info.txt') as info_fh:\n",
    "        header = info_fh.readline()\n",
    "        header = header.split('\\t')\n",
    "        print(header)\n",
    "        info_reader = csv.reader(info_fh, delimiter = '\\t')\n",
    "        i = 0\n",
    "\n",
    "        # Set columns\n",
    "        site_id_col = 0\n",
    "        contig_col = 1\n",
    "        pos_col = 2\n",
    "        ref_allele_col = 3\n",
    "        major_allele_col = 4\n",
    "        minor_allele_col = 5\n",
    "        locus_type_col = 11\n",
    "        gene_id_col = 12\n",
    "        aminoacids_col = 15\n",
    "\n",
    "        print(\"============HEADERs============\")\n",
    "        print(\">Site id: {}\".format(header[site_id_col]))\n",
    "        print(\">Contig: {}\".format(header[contig_col]))\n",
    "        print(\">Position: {}\".format(header[pos_col]))\n",
    "        print(\">Ref allele: {}\".format(header[ref_allele_col]))\n",
    "        print(\">Major allele: {}\".format(header[major_allele_col]))\n",
    "        print(\">Minor allele: {}\".format(header[minor_allele_col]))\n",
    "        print(\">Locus type: {}\".format(header[locus_type_col]))\n",
    "        print(\">Gene id: {}\".format(header[gene_id_col]))\n",
    "        print(\">Aminoacids: {}\".format(header[aminoacids_col]))\n",
    "\n",
    "        #\n",
    "        for row in info_reader:\n",
    "            i += 1\n",
    "            if i > args.nrows:\n",
    "                break\n",
    "            #print(row)\n",
    "            #print(row[gene_id_col], row[site_id_col])\n",
    "            #print(row[aminoacids_col])\n",
    "            gene = row[gene_id_col]\n",
    "            site_id = row[site_id_col]\n",
    "            aminoacids = row[aminoacids_col]\n",
    "            #print(aminoacids)\n",
    "            #print(site_id)\n",
    "\n",
    "            if gene == 'NA':\n",
    "                # skip intergenig regions\n",
    "                continue\n",
    "\n",
    "            #print(\"\\tgene\")\n",
    "            # Get aminoacid per position\n",
    "            aa = aminoacids.split(',')\n",
    "            #print(aa)\n",
    "\n",
    "            # Define site\n",
    "            #print(site_id)\n",
    "            Sites[site_id] = GenomeSite(site_id = site_id,\n",
    "                                        contig = row[contig_col],\n",
    "                                        position = row[pos_col],\n",
    "                                        ref_allele = row[ref_allele_col],\n",
    "                                        major_allele = row[major_allele_col],\n",
    "                                        minor_allele = row[minor_allele_col],\n",
    "                                        locus_type = row[locus_type_col],\n",
    "                                        gene_id = gene, aminoacid_A = aa[0],\n",
    "                                        aminoacid_C = aa[1],\n",
    "                                        aminoacid_G = aa[2],\n",
    "                                        aminoacid_T = aa[3])\n",
    "\n",
    "            # For genes\n",
    "            if gene in Genes:\n",
    "                # update genes\n",
    "                Genes[gene].extend(row[pos_col])\n",
    "                #print(gene)\n",
    "                #print(Genes[gene])\n",
    "                #Genes[gene].print()\n",
    "\n",
    "            else:\n",
    "                # Define gene\n",
    "                Genes[gene] = Gene(gene_id=gene, contig = row[contig_col],\n",
    "                                   start = row[pos_col], end = row[pos_col])\n",
    "                #Genes[gene].print()\n",
    "                #print(Genes[gene])\n",
    "\n",
    "\n",
    "    info_fh.close()\n",
    "    #print(Groups)\n",
    "    print(\"Number of sites: {}\".format(str(len(Sites))))\n",
    "    print(\"Number of genes: {}\".format(str(len(Genes))))\n",
    "    \n",
    "    ###### Chose sites based on depth in groups to compare #######\n",
    "    Counts = {}\n",
    "    with open(args.indir + '/snps_depth.txt') as depth_fh:\n",
    "        header = depth_fh.readline()\n",
    "        header = header.rstrip()\n",
    "        header = header.split('\\t')\n",
    "\n",
    "        # Get sample and column indices\n",
    "        samples = header[1:]\n",
    "        indices = {}\n",
    "        for s in samples:\n",
    "            indices[s] = header.index(s)\n",
    "        print(indices)\n",
    "\n",
    "\n",
    "        depth_reader = csv.reader(depth_fh, delimiter = '\\t')\n",
    "        i = 0\n",
    "        for row in depth_reader:\n",
    "            i += 1\n",
    "            if i > args.nrows:\n",
    "                break \n",
    "            #print(row)\n",
    "\n",
    "            site_id = row[0]\n",
    "            #print(site_id)\n",
    "            if not site_id in Sites:\n",
    "                continue\n",
    "\n",
    "            # Get all counts\n",
    "            counts = row[1:]\n",
    "            counts = list(map(int,counts))\n",
    "            #print(counts)\n",
    "\n",
    "            counts = [int(c >= args.min_count) for c in counts]\n",
    "\n",
    "            # Get counts per group\n",
    "            samples1 = [int(counts[ indices[l] - 1 ]) for l in Groups[args.group1]]\n",
    "            samples2 = [int(counts[ indices[l] - 1 ]) for l in Groups[args.group2]]\n",
    "            samples1 = sum(samples1)\n",
    "            samples2 = sum(samples2)\n",
    "            #print(samples1)\n",
    "            #print(samples2)\n",
    "            if not ((samples1 > 0 and samples2 > 0) and (samples1 > 1 or samples2 > 1)):\n",
    "                # delete\n",
    "                #print(site_id)\n",
    "                if site_id in Sites:\n",
    "                    del Sites[site_id]\n",
    "            else:\n",
    "                # NOTE: ASSUMING SAME ORDER IN SAMPLES BETWEEN SITES\n",
    "                Counts[site_id] = counts\n",
    "\n",
    "\n",
    "\n",
    "    depth_fh.close()\n",
    "    print(\"Number of sites: {}\".format(str(len(Sites))))\n",
    "    print(\"Number of genes: {}\".format(str(len(Genes))))\n",
    "    print(\"Sites with counts: {}\".format(str(len(Counts))))\n",
    "    \n",
    "    # Read frequencies and calculate \n",
    "    print(Groups)\n",
    "    MK = {}\n",
    "    with open(args.indir + '/snps_freq.txt') as freqs_fh:\n",
    "        header = freqs_fh.readline()\n",
    "        header = header.rstrip()\n",
    "        header = header.split('\\t')\n",
    "\n",
    "        # Get sample and column indices\n",
    "        samples = header[1:]\n",
    "        indices = {}\n",
    "        for s in samples:\n",
    "            indices[s] = header.index(s)\n",
    "        print(indices)\n",
    "        print(header)\n",
    "\n",
    "        freqs_reader = csv.reader(freqs_fh, delimiter = '\\t')\n",
    "        i = 0\n",
    "        for row in freqs_reader:\n",
    "            i += 1\n",
    "            if i > args.nrows:\n",
    "                break\n",
    "\n",
    "            # Check if site was selected based on sites\n",
    "            site_id = row[0]\n",
    "            if not site_id in Sites:\n",
    "                #print(\"==Skipping\")\n",
    "                continue\n",
    "\n",
    "            gene = Sites[site_id].gene_id\n",
    "            s_type = Sites[site_id].substitution_type()\n",
    "            present_index = np.array(Counts[site_id])\n",
    "            group_index = np.array([Samples[s][0] for s in samples])\n",
    "    #         if site_id == '77719':\n",
    "    #             print(\"==========================\")\n",
    "    #             print(row)\n",
    "    #             print(site_id)\n",
    "    #             print(\"Major Allele: {}\".format(Sites[site_id].major_allele))\n",
    "    #             print(\"Minor Allele: {}\".format(Sites[site_id].minor_allele))\n",
    "    #             print(\"Substitution type: {}\".format(s_type))\n",
    "    #             print(\"Gene: {}\".format(gene))\n",
    "    #             print(present_index)\n",
    "    #             print(group_index)\n",
    "\n",
    "            # Create MKtest if needed\n",
    "            if gene not in MK:\n",
    "                MK[gene]= MKtest(name=gene)\n",
    "\n",
    "            # find allele per sample\n",
    "            allele_freqs = np.array([int(float(f) < 0.5) for f in row[1:]])\n",
    "            #print(allele_freqs)\n",
    "\n",
    "            # Remove non covered positions\n",
    "            ii = np.where(present_index)\n",
    "            group_index = group_index[ii]\n",
    "            allele_freqs = allele_freqs[ii]\n",
    "            #print(group_index)\n",
    "            #print(allele_freqs)\n",
    "\n",
    "            # Count alleles per group\n",
    "            group1_count = allele_freqs[np.where(group_index == args.group1)].sum()\n",
    "            group2_count = allele_freqs[np.where(group_index == args.group2)].sum()\n",
    "            #print(group1_count)\n",
    "            #print(group2_count)\n",
    "\n",
    "            if group1_count > 0 and group2_count > 0:\n",
    "                fixed = False\n",
    "            elif group1_count > 0 or group2_count > 0:\n",
    "                fixed = True\n",
    "\n",
    "            if s_type == 'synonymous':\n",
    "                if fixed:\n",
    "                    MK[gene].update(Ds = 1)\n",
    "                else:\n",
    "                    MK[gene].update(Ps = 1)\n",
    "            elif s_type == 'non-synonymous':\n",
    "                if fixed:\n",
    "                    MK[gene].update(Dn = 1)\n",
    "                else:\n",
    "                    MK[gene].update(Pn = 1)\n",
    "            else:\n",
    "                raise ValueError(\"Invalid substitution type\")\n",
    "\n",
    "            #print(\"==========================\")\n",
    "\n",
    "\n",
    "\n",
    "    freqs_fh.close()\n",
    "    print(\"Number of sites: {}\".format(str(len(Sites))))\n",
    "    print(\"Number of genes: {}\".format(str(len(Genes))))\n",
    "    print(\"Sites with counts: {}\".format(str(len(Counts))))\n",
    "    print(\"Genes with MK: {}\".format(str(len(MK))))\n",
    "    \n",
    "    ################ Test and results ########\n",
    "    with open(args.outfile,mode='w') as fh, open(args.tables,mode='w') as th:\n",
    "        header = ['gene','contig','start','end',\n",
    "                  'ni', 'ratio','ratio_pseudo','hg_odds','hg_p','hg_odds_pseudo','hg_p_pseudo',\n",
    "                  'g_none_p','g_yates_p','g_williams_p',\n",
    "                  'g_none_p_pseudo','g_yates_p_pseudo','g_williams_p_pseudo',\n",
    "                  'alpha','alpha_pseudo']\n",
    "        fh.write(\"\\t\".join(header) + \"\\n\")\n",
    "        for gene,mk in MK.items():\n",
    "            th.write(\"=============================================\\n\")\n",
    "            th.write(gene)\n",
    "            th.write(\"\\t\\tFixed\\tPolymorphic\\n\\tSynonymous\\t{}\\t{}\\n\\tnon-synonymous\\t{}\\t{}\\n\".format(mk.Ds,mk.Ps,mk.Dn,mk.Pn))\n",
    "\n",
    "            # Calculate neutrality index\n",
    "            try:\n",
    "                ni = mk.neutrality_index(log=True, pseudocount = args.pseudocount)\n",
    "            except ZeroDivisionError:\n",
    "                ni = float('nan')\n",
    "\n",
    "            # Calculate ratio with and without pseudocount\n",
    "            try:\n",
    "                ratio = mk.mk_ratio(pseudocount=0)\n",
    "            except ZeroDivisionError:\n",
    "                ratio = float('nan')\n",
    "            try:\n",
    "                ratio_pseudo = mk.mk_ratio(pseudocount=args.pseudocount)\n",
    "            except ZeroDivisionError:\n",
    "                ratio = float('nan')\n",
    "\n",
    "            # Hypergeometric test\n",
    "            hg_odds, hg_p = mk.hg_test(pseudocount = 0)\n",
    "            hg_odds_pseudo, hg_p_pseudo = mk.hg_test(pseudocount = args.pseudocount)\n",
    "\n",
    "            # G test of indenpendece try multiple corrections\n",
    "            try:\n",
    "                g_none, g_none_p, g_none_df, g_none_E = mk.g_test(correction='none',\n",
    "                                                                  pseudocount=0)\n",
    "            except ValueError:\n",
    "                g_none = float('nan')\n",
    "                g_none_p = float('nan')\n",
    "                g_none_df = float('nan')\n",
    "                g_none_E = float('nan')\n",
    "\n",
    "            try:\n",
    "                g_yates, g_yates_p, g_yates_df, g_yates_E = mk.g_test(correction='yates',\n",
    "                                                                      pseudocount=0)\n",
    "            except ValueError:\n",
    "                g_yates = float('nan')\n",
    "                g_yates_p = float('nan')\n",
    "                g_yates_df = float('nan')\n",
    "                g_yates_E = float('nan')\n",
    "\n",
    "            try:\n",
    "                g_williams, g_williams_p, g_williams_df, g_williams_E = mk.g_test(correction='williams',\n",
    "                                                                                  pseudocount=0)\n",
    "            except ValueError:\n",
    "                g_williams = float('nan')\n",
    "                g_williams_p = float('nan')\n",
    "                g_williams_df = float('nan')\n",
    "                g_williams_E = float('nan')\n",
    "\n",
    "            # G test for independence with pseududocounts        \n",
    "            try:\n",
    "                g_none_pseudo, g_none_p_pseudo, g_none_df_pseudo, g_none_E_pseudo = mk.g_test(correction='none',\n",
    "                                                                                              pseudocount=args.pseudocount)\n",
    "            except ValueError:\n",
    "                g_none_pseudo = float('nan')\n",
    "                g_none_p_pseudo = float('nan')\n",
    "                g_none_df_pseudo = float('nan')\n",
    "                g_none_E_pseudo = float('nan')\n",
    "\n",
    "            try:\n",
    "                g_yates_pseudo, g_yates_p_pseudo, g_yates_df_pseudo, g_yates_E_pseudo = mk.g_test(correction='yates',\n",
    "                                                                                                  pseudocount=args.pseudocount)\n",
    "            except ValueError:\n",
    "                g_yates_pseudo = float('nan')\n",
    "                g_yates_p_pseudo = float('nan')\n",
    "                g_yates_df_pseudo = float('nan')\n",
    "                g_yates_E_pseudo = float('nan')\n",
    "\n",
    "            try:\n",
    "                g_williams_pseudo, g_williams_p_pseudo, g_williams_df_pseudo, g_williams_E_pseudo = mk.g_test(correction='williams',\n",
    "                                                                                                              pseudocount=args.pseudocount)                                \n",
    "            except ValueError:\n",
    "                g_williams_pseudo = float('nan')\n",
    "                g_williams_p_pseudo = float('nan')\n",
    "                g_williams_df_pseudo = float('nan')\n",
    "                g_williams_E_pseudo = float('nan')\n",
    "\n",
    "\n",
    "            # Eyre-Walker alpha\n",
    "            alpha = mk.alpha(pseudocount=0)\n",
    "            alpha_pseudo = mk.alpha(pseudocount=args.pseudocount)\n",
    "\n",
    "            # prepare res        \n",
    "            res = [gene, Genes[gene].contig, str(Genes[gene].start), str(Genes[gene].end),\n",
    "                   str(ni), str(ratio), str(ratio_pseudo),\n",
    "                   str(hg_odds), str(hg_p), str(hg_odds_pseudo),str(hg_p_pseudo),\n",
    "                   str(g_none_p), str(g_yates_p),str(g_williams_p),\n",
    "                   str(g_none_p_pseudo), str(g_yates_p_pseudo),str(g_williams_p_pseudo),\n",
    "                   str(alpha), str(alpha_pseudo)]\n",
    "\n",
    "            th.write(str(res) + \"\\n\")\n",
    "            fh.write(\"\\t\".join(res) + \"\\n\")\n",
    "            #alpha = mk.alpha()\n",
    "            #print(\"MK ratio is: {}\".format(str(ratio)))\n",
    "            #print(\"MK alpha is: {}\".format(str(alpha)))\n",
    "    fh.close()\n",
    "    th.close()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
